{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification And Regression Tree (CART)\n",
    "\n",
    "## Tree-based Methods\n",
    "\n",
    "**CART**: **C**lassification **A**nd **R**egression **T**ree\n",
    "\n",
    "### Grow a binary tree\n",
    "\n",
    "- At each node, ‚Äúsplit‚Äù the data into two ‚Äúdaughter‚Äù nodes.\n",
    "- Splits are chosen using a splitting criterion.\n",
    "- Bottom nodes are ‚Äúterminal‚Äù nodes.\n",
    "\n",
    "|                    | Type of tree    | Predicted value at a node                                    | Split criterion                                              |\n",
    "| ------------------ | --------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n",
    "| **Regression**     | Regression tree | The predicted value at a node is the **average response** variable for all observations in the node | **Minimum residual sum of squares** <br />$$\\mathrm{RSS}=\\sum_{\\text {left }}\\left(y_{i}-\\bar{y}_{L}\\right)^{2}+\\sum_{\\text {right }}\\left(y_{i}-\\bar{y}_{R}\\right)^{2}$$<li />$\\bar{y}_L$ / $\\bar{y}_R$: average label values in the left / right subtree <br />(Split such that variance in subtress is minimized) |\n",
    "| **Classification** | Decision tree   | The predicted class is the **most common class** in the node (majority vote). | **Minimum entropy** in subtrees<br />$$\\text { score }=N_{L} H\\left(p_{\\mathrm{L}}\\right)+N_{R} H\\left(p_{\\mathrm{R}}\\right)$$<li />$H\\left(p_{L}\\right)=-\\sum_{k} p_{L}(k) \\log p_{L}(k)$: entropy in the left sub-tree <li /> $p_L(k)$: proportion of class $k$ in left tree<br />(Split such that class-labels in sub-trees are \"pure\") |\n",
    "\n",
    "### When stop?\n",
    "\n",
    "**Stop if:**\n",
    "\n",
    "- Minimum number of samples per node\n",
    "- Maximum depth \n",
    "\n",
    "... has been reached\n",
    "\n",
    "(Both criterias again influence the **complexity** of the tree)\n",
    "\n",
    "### Controlling the tree complexity\n",
    "\n",
    "| Number of samples per leaf | Affect                              |                                                              |\n",
    "| -------------------------- | ----------------------------------- | ------------------------------------------------------------ |\n",
    "| **Small**                  | Tree is **very sensitive** to noise | <img src=\"https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/Â±èÂπïÂø´ÁÖß%202020-03-01%2023.26.23.png\" alt=\"Â±èÂπïÂø´ÁÖß 2020-03-01 23.26.23\" style=\"zoom:33%;\" /><br /><img src=\"https://github.com/EckoTan0804/upic-repo/blob/master/uPic/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202020-03-01%2023.25.40.png?raw=true\" alt=\"Â±èÂπïÂø´ÁÖß 2020-03-01 23.25.40.png\" style=\"zoom:33%;\" /> |\n",
    "| **Large**                  | Tree is **not expressive enough**   | <img src=\"https://raw.githubusercontent.com/EckoTan0804/upic-repo/master/uPic/Â±èÂπïÂø´ÁÖß%202020-03-01%2023.25.50.png\" alt=\"Â±èÂπïÂø´ÁÖß 2020-03-01 23.25.50\" style=\"zoom:33%;\" /> |\n",
    "\n",
    "\n",
    "\n",
    "### Advantages üëç\n",
    "\n",
    "- Applicable to both regression and classification problems.\n",
    "\n",
    "- Handle categorical predictors naturally.\n",
    "\n",
    "- Computationally simple and quick to fit, even for large problems.\n",
    "\n",
    "- No formal distributional assumptions (non-parametric).\n",
    "\n",
    "- Can handle highly non-linear interactions and classification boundaries.\n",
    "\n",
    "- Automatic variable selection.\n",
    "\n",
    "- Very easy to interpret if the tree is small.\n",
    "\n",
    "### Disadvantages üëé\n",
    "\n",
    "- ***Accuracy*** \n",
    "\n",
    "  current methods, such as support vector machines and ensemble classifiers often have 30% lower error rates than CART.\n",
    "\n",
    "- ***Instability*** \n",
    "\n",
    "  if we change the data a little, the tree picture can change a lot. So the interpretation is not as straightforward as it appears."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
