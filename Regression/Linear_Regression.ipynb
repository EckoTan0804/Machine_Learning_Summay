{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Model\n",
    "\n",
    "A linear model makes a prediction $\\hat{y}_i$ by **simply computing a weighted sum of the input $\\boldsymbol{x}_i$, plus a constant $w_0$ called the _bias_ term**:\n",
    "\n",
    "### For single samples / instances\n",
    "$\\hat{y}_i = f\\left(\\boldsymbol{x}_{i}\\right)=w_{0}+\\displaystyle \\sum_{j}^D w_{j} x_{i, j}$\n",
    "\n",
    "In matrix-form:\n",
    "$\\hat{y}_{i}=w_{0}+ \\displaystyle \\sum_{j=1}^{D} w_{j} x_{i, j}=\\tilde{\\boldsymbol{x}}_{i}^{T} \\boldsymbol{w}\\\n",
    "$\n",
    "\n",
    "- $\\tilde{\\boldsymbol{x}}_{i} = \\left[\\begin{array}{c}{1} \\\\ {x_{i}}\\end{array}\\right] = \\left[\\begin{array}{c} {1} \\\\ x_{i, 1} \\\\ \\vdots \\\\ {x_{i, D}}\\end{array}\\right] \\in \\mathbb{R}^{D+1}$\n",
    "\n",
    "- $\\boldsymbol{w}=\\left[\\begin{array}{c}{w_{0}} \\\\ {\\vdots} \\\\ {w_{D}}\\end{array}\\right] \\in \\mathbb{R}^{D+1}$\n",
    "\n",
    "### On full dataset\n",
    "\n",
    "$\n",
    "\\hat{\\boldsymbol{y}}=\\left[\\begin{array}{c}{\\hat{y}_{1}} \\\\ {\\vdots} \\\\ {\\hat{y}_{n}}\\end{array}\\right]=\\left[\\begin{array}{c}{\\tilde{\\boldsymbol{x}}_{1}^{T} \\boldsymbol{w}} \\\\ {\\vdots} \\\\ {\\tilde{\\boldsymbol{x}}_{n}^{T} \\boldsymbol{w}}\\end{array}\\right] = \\underbrace{\\left[\\begin{array}{cc}{1} & {\\boldsymbol{x}_{1}^{T}} \\\\ {\\vdots} & {\\vdots} \\\\ {1} & {\\boldsymbol{x}_{n}^{T}}\\end{array}\\right]}_{=: \\boldsymbol{X}} \\boldsymbol{w} = \\boldsymbol{X} \\boldsymbol{w}\n",
    "$\n",
    "- $\\hat{\\boldsymbol{y}}$: vector containing the output for each sample\n",
    "- $\\boldsymbol{X}$: data-matrix containing a vector of ones as the first column as bias\n",
    "\n",
    "> $y=\\underbrace{\\begin{bmatrix}{\\widehat y}_1\\\\\\vdots\\\\{\\widehat y}_n\\end{bmatrix}}_{\\boldsymbol\\in\\mathbf ‚Ñù^{n\\times1}}=\\begin{bmatrix}\\widehat x_1^Tw\\\\\\vdots\\\\\\widehat x_n^Tw\\end{bmatrix}=\\begin{bmatrix}1\\cdot w_0+x_{1,1}\\cdot w_1+\\cdots+x_{1,D}\\cdot w_D\\\\\\vdots\\\\1\\cdot w_0+x_{n,1}\\cdot w_1+\\cdots+x_{n,D}\\cdot w_D\\end{bmatrix}=\\underset{=\\begin{bmatrix}1&x_1^T\\\\\\vdots&\\vdots\\\\1&x_n^T\\end{bmatrix}\\\\=:\\boldsymbol X\\in\\mathbb{R}^{n\\times(1+D)}}{\\underbrace{\\begin{bmatrix}1&x_{1,1}&\\cdots&x_{1,D}\\\\\\vdots&\\vdots&\\ddots&\\vdots\\\\1&x_{n,1}&\\cdots&x_{n,D}\\end{bmatrix}}\\cdot}\\underbrace{\\begin{bmatrix}w_0\\\\w_1\\\\\\vdots\\\\w_D\\end{bmatrix}}_{=:\\boldsymbol w\\boldsymbol\\in\\mathbf ‚Ñù^{\\boldsymbol(\\mathbf1\\boldsymbol+\\mathbf D\\boldsymbol)\\boldsymbol\\times\\mathbf1}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal value of $\\boldsymbol{w}$\n",
    "\n",
    "Error vector:\n",
    "\n",
    "$\n",
    "\\boldsymbol{e}=\\left[\\begin{array}{c}{y_{1}} \\\\ {\\vdots} \\\\ {y_{n}}\\end{array}\\right]-\\left[\\begin{array}{c}{\\hat{y}_{1}} \\\\ {\\vdots} \\\\ {\\hat{y}_{n}}\\end{array}\\right]=\\boldsymbol{y}-\\hat{\\boldsymbol{y}}=\\boldsymbol{y}-\\boldsymbol{X} \\boldsymbol{w}\n",
    "$\n",
    "\n",
    " **Summed Square Error (SSE)**:\n",
    " \n",
    " $\n",
    " \\mathrm{SSE}=\\sum_{i}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}=\\sum_{i} e_{i}^{2}=e^{T} e=(y-X w)^{T}(y-X w)\n",
    " $\n",
    "\n",
    "Solution: the **Normal Equation**: \n",
    "---\n",
    "\n",
    "$\n",
    "\\boldsymbol{w}^{*} = \\underset{\\boldsymbol{w}}{\\operatorname{argmin}} \\operatorname{SSE} = (\\boldsymbol{X}^{T} \\boldsymbol{X})^{-1}\\boldsymbol{X}^{T} \\boldsymbol{y}\\qquad \\text{\"Least Squares solution\"}\n",
    "$\n",
    "\n",
    "\n",
    "> Derivation: Find a $\\boldsymbol{w}$ where $\\frac{\\partial \\mathrm{SSE}}{\\partial \\boldsymbol{w}}=\\mathbf{0}^{T}$ \n",
    ">\n",
    "> $\\begin{equation}  \\begin{aligned}     \\operatorname{SSE}(\\boldsymbol{w}) &=(\\boldsymbol{y}-\\boldsymbol{X} \\boldsymbol{w})^{T}(\\boldsymbol{y}-\\boldsymbol{X} \\boldsymbol{w}) \\\\     &=\\boldsymbol{w}^{T} \\boldsymbol{X}^{T} \\boldsymbol{X} \\boldsymbol{w}- \\underbrace{\\boldsymbol{y}^{T} \\boldsymbol{X} \\boldsymbol{w}}_{\\in \\mathbb{R}} -\\underbrace{\\boldsymbol{w}^{T} \\boldsymbol{X}^{T} \\boldsymbol{y}}_{\\in \\mathbb{R}} +\\boldsymbol{y}^{T} \\boldsymbol{y} \\\\     &=\\boldsymbol{w}^{T} \\boldsymbol{X}^{T} \\boldsymbol{X} \\boldsymbol{w}- \\boldsymbol{y}^{T} \\boldsymbol{X} \\boldsymbol{w} - (\\boldsymbol{y}^{T} \\boldsymbol{X} \\boldsymbol{w})^T +\\boldsymbol{y}^{T} \\boldsymbol{y} \\\\    &=\\boldsymbol{w}^{T} \\boldsymbol{X}^{T} \\boldsymbol{X} \\boldsymbol{w}- \\boldsymbol{y}^{T} \\boldsymbol{X} \\boldsymbol{w} - \\boldsymbol{y}^{T} \\boldsymbol{X} \\boldsymbol{w}+\\boldsymbol{y}^{T} \\boldsymbol{y} \\\\    &=\\boldsymbol{w}^{T} \\boldsymbol{X}^{T} \\boldsymbol{X} \\boldsymbol{w}-2 \\boldsymbol{y}^{T} \\boldsymbol{X} \\boldsymbol{w}+\\boldsymbol{y}^{T} \\boldsymbol{y}   \\end{aligned}\\end{equation}$\n",
    ">\n",
    "> $\\begin{aligned}  \\\\ \\nabla_{\\boldsymbol{w}} \\operatorname{SSE}(\\boldsymbol{w}) &=\\frac{\\partial}{\\partial \\boldsymbol{w}}\\left\\{\\boldsymbol{w}^{T} \\boldsymbol{X}^{T} \\boldsymbol{X} \\boldsymbol{w}-2 \\boldsymbol{y}^{T} \\boldsymbol{X} \\boldsymbol{w}+\\boldsymbol{y}^{T} \\boldsymbol{y}\\right\\} \\\\ &= 2\\boldsymbol{X}^{T} \\boldsymbol{X} \\boldsymbol{w}- 2\\boldsymbol{X}^{T} \\boldsymbol{y} \\overset{!}{=}0 \\end{aligned}$ \n",
    "> \n",
    "> $\\Leftrightarrow \\boldsymbol{w} = (\\boldsymbol{X}^{T} \\boldsymbol{X})^{-1}\\boldsymbol{X}^{T} \\boldsymbol{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "**R-Square ($R^2$)**\n",
    "\n",
    "$\n",
    "R^{2}=1-\\frac{\\text { Regression sum of squares }}{\\text { Total sum of squares }}=1-\\frac{\\displaystyle \\sum_{n=1}^{N}\\left(\\hat{y}_{n}-y_{n}\\right)^{2}}{\\displaystyle \\sum_{n=1}^{N}(y_{n}-\\underbrace{\\bar{y}}_{\\text{mean of the outputs}})^{2}}\n",
    "$\n",
    "\n",
    "($\\hat{\\boldsymbol{y}}$: vector containing the output for each sample)\n",
    "\n",
    "- Determines how much of the total variation in $ùë¶$ is explained by the variation in $ùë•$\n",
    "- Tells how well the regression line approximates the real data points\n",
    "  - An $R^2$ of 1 indicates that the regression line perfectly fits the data üëç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
